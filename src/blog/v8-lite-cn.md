***

标题： “更轻的V8”
作者：Mythri Alle，Dan Elphick和[罗斯·麦克罗伊](https://twitter.com/rossmcilroy)，V8重量观察者
化身：

*   'mythri-alle'
*   '丹-埃尔菲克'
*   “罗斯-麦克罗伊”
    日期： 2019-09-12 12：44：37
    标签：
*   内部
*   记忆
*   介绍
    描述： “V8 Lite 项目大大降低了 V8 在典型网站上的内存开销，这就是我们的做法。
    推文：“1172155403343298561”

***

在2018年底，我们启动了一个名为V8 Lite的项目，旨在大幅减少V8的内存使用量。最初，该项目被设想为一个单独的项目。*精简模式*的 V8 专门针对低内存移动设备或嵌入器用例，这些用例更关心降低内存使用量而不是吞吐量执行速度。但是，在这项工作的过程中，我们意识到我们为此所做的许多内存优化。*精简模式*可以带到常规V8，从而使V8的所有用户受益。

在这篇文章中，我们将重点介绍我们开发的一些关键优化以及它们在实际工作负载中提供的内存节省。

：：：备注
**注意：**如果您更喜欢观看演示文稿而不是阅读文章，那么请欣赏下面的视频！如果没有，请跳过视频并继续阅读。
:::

<figure>
  <div class="video video-16:9">
    <iframe width="560" height="315" src="https://www.youtube.com/embed/56ogP8-eRqA" allow="picture-in-picture" allowfullscreen loading="lazy"></iframe>
  </div>
  <figcaption><a href="https://www.youtube.com/watch?v=56ogP8-eRqA">“V8 Lite  ⁠— slimming down JavaScript memory”</a> as presented by Ross McIlroy at BlinkOn 10.</figcaption>
</figure>

## 精简模式

为了优化 V8 的内存使用率，我们首先需要了解 V8 如何使用内存，以及哪些对象类型在 V8 的堆大小中占很大比例。我们使用了 V8 的[内存可视化](/blog/optimizing-v8-memory#memory-visualization)工具来跟踪许多典型网页中的堆组成。

<figure>
  <img src="/_img/v8-lite/memory-categorization.svg" width="950" height="440" alt="" loading="lazy">
  <figcaption>Percentage of V8’s heap used by different object types when loading Times of India.</figcaption>
</figure>

在这样做的过程中，我们确定 V8 堆的很大一部分专用于对 JavaScript 执行不是必需的对象，而是用于优化 JavaScript 执行和处理异常情况的对象。示例包括：优化代码;用于确定如何优化代码的类型反馈;用于C++和JavaScript对象之间绑定的冗余元数据;仅在特殊情况下需要元数据，例如堆栈跟踪符号化;和字节码，用于在页面加载期间仅执行几次的函数。

因此，我们开始研究*精简模式*的 V8，它通过大大减少这些可选对象的分配来权衡 JavaScript 的执行速度与改进的内存节省。

![](../_img/v8-lite/v8-lite.png){ .no-darkening }

一些*精简模式*可以通过配置现有的V8设置进行更改，例如，禁用V8的TurboFan优化编译器。但是，其他人需要对V8进行更复杂的更改。

特别是，我们决定*精简模式*不优化代码，我们可以避免收集优化编译器所需的类型反馈。在 Ignition 解释器中执行代码时，V8 收集有关传递给各种操作的操作数类型的反馈（例如，`+`或`o.foo`），以便为这些类型定制后续优化。此信息存储在*反馈向量*这贡献了 V8 堆内存使用量的很大一部分。*精简模式*可以避免分配这些反馈向量，但是解释器和 V8 的内联缓存基础结构的一部分期望反馈向量可用，因此需要大量的重构才能支持这种无反馈的执行。

*精简模式*在 V8 v7.3 中启动，通过禁用代码优化、不分配反馈向量和执行很少执行的字节码老化（如下所述），与 V8 v7.1 相比，典型网页堆大小减少了 22%。对于那些明确想要牺牲性能以获得更好的内存利用率的应用程序来说，这是一个不错的结果。然而，在做这项工作的过程中，我们意识到我们可以实现大部分内存节省*精简模式*不会因使 V8 更懒惰而对性能造成任何影响。

## 懒惰反馈分配

完全禁用反馈向量分配不仅会阻止 V8 的 TurboFan 编译器优化代码，还会阻止 V8 执行[内联缓存](https://mathiasbynens.be/notes/shapes-ics#ics)的常见操作，例如 Ignition 解释器中的对象属性加载。因此，这样做会导致 V8 的执行时间显著下降，将页面加载时间缩短了 12%，在典型的交互式网页场景中，V8 使用的 CPU 时间增加了 120%。

为了在没有这些回归的情况下将这些节省的大部分成本带到常规V8，我们转而采用一种方法，即在函数执行一定量的字节码（目前为1KB）后，我们懒惰地分配反馈向量。由于大多数函数不经常执行，因此在大多数情况下，我们避免了反馈向量分配，而是在需要时快速分配它们，以避免性能回归，并且仍然允许代码得到优化。

这种方法的另一个复杂之处在于，反馈向量形成一棵树，内部函数的反馈向量在其外部函数的反馈向量中作为条目保存。这是必要的，以便新创建的函数闭包接收与为同一函数创建的所有其他闭包相同的反馈向量数组。对于反馈向量的延迟分配，我们不能使用反馈向量形成此树，因为不能保证外部函数在内部函数这样做时已经分配了其反馈向量。为了解决这个问题，我们创建了一个新的`ClosureFeedbackCellArray`来维护此树，然后换出函数的`ClosureFeedbackCellArray`与一个完整的`FeedbackVector`当它变热时。

![Feedback vector trees before and after lazy feedback allocation.](../_img/v8-lite/lazy-feedback.svg)

我们的实验室实验和现场遥测显示，桌面上的惰性反馈没有性能回归，在移动平台上，由于垃圾回收的减少，我们实际上看到了低端设备的性能提高。因此，我们在 V8 的所有版本中都启用了惰性反馈分配，包括*精简模式*与我们最初的无反馈分配方法相比，内存中的轻微回归被现实世界性能的改进所弥补。

## 懒惰的源位置

从 JavaScript 编译字节码时，会生成源位置表，将字节码序列与 JavaScript 源代码中的字符位置相关联。但是，只有在对异常进行符号化或执行开发人员任务（如调试）时才需要此信息，因此很少使用。

为了避免这种浪费，我们现在编译字节码而不收集源位置（假设没有附加调试器或探查器）。仅当实际生成堆栈跟踪时（例如，在调用时），才会收集源位置`Error.stack`或将异常的堆栈跟踪打印到控制台。这确实有一些成本，因为生成源位置需要重新分析和编译函数，但是大多数网站不会在生产中对堆栈跟踪进行符号化，因此看不到任何可观察到的性能影响。

我们在这项工作中必须解决的一个问题是要求可重复的字节码生成，这在以前是无法保证的。如果 V8 在收集源位置时生成了与原始代码不同的字节码，则源位置不会对齐，并且堆栈跟踪可能指向源代码中的错误位置。

在某些情况下，V8 可以生成不同的字节码，具体取决于函数是否[急切或懒惰地编译](/blog/preparser#skipping-inner-functions)，由于在函数的初始预先解析和后来的延迟编译之间丢失了一些解析器信息。这些不匹配大多是良性的，例如，忘记了变量是不可变的，因此无法对其进行优化。但是，这项工作发现的一些不匹配在某些情况下确实有可能导致不正确的代码执行。因此，我们修复了这些不匹配，并添加了检查和压力模式，以确保函数的急切和懒惰编译始终产生一致的输出，这使我们对 V8 的解析器和准备器的正确性和一致性更有信心。

## 字节码刷新

从 JavaScript 源代码编译的字节码占用了大量 V8 堆空间，通常约为 15%，包括相关元数据。有许多函数仅在初始化期间执行，或者在编译后很少使用。

因此，我们添加了对在垃圾回收期间从函数中刷新已编译字节码（如果它们最近未执行）的支持。为此，我们跟踪*年龄*函数的字节码，递增*年龄*每[主要（标记紧凑）](/blog/trash-talk#major-gc)垃圾回收，并在执行函数时将其重置为零。任何超过老化阈值的字节码都有资格被下一个垃圾回收收集。如果它被收集，然后再次执行，它将被重新编译。

在确保字节码仅在不再需要时才刷新字节码存在技术挑战。例如，如果函数`A`调用另一个长时间运行的函数`B`功能`A`当它仍在堆栈上时可能会老化。我们不想刷新函数的字节码`A`即使它达到其老化阈值，因为我们需要在长时间运行时返回它的功能`B`返回。因此，我们将字节码视为在函数达到其老化阈值时从函数中弱持有，但由堆栈或其他地方对它的任何引用强烈持有。我们只在没有剩余强链接的情况下刷新代码。

除了刷新字节码之外，我们还刷新了与这些刷新函数关联的反馈向量。但是，我们无法在与字节码相同的GC周期内刷新反馈向量，因为它们不由同一对象保留 - 字节码由独立于本机上下文的字节保持`SharedFunctionInfo`，而反馈向量由原生上下文相关`JSFunction`.因此，我们在随后的GC循环中刷新反馈向量。

![The object layout for an aged function after two GC cycles.](../_img/v8-lite/bytecode-flushing.svg)

## 其他优化

除了这些大型项目外，我们还发现并解决了一些效率低下的问题。

首先是减小尺寸`FunctionTemplateInfo`对象。这些对象存储有关[`FunctionTemplate`s](/docs/embed#templates)，用于使嵌入器（如 Chrome）能够提供可由 JavaScript 代码调用的函数的C++回调实现。Chrome引入了许多函数模板来实现DOM Web API，因此`FunctionTemplateInfo`对象促成了 V8 的堆大小。在分析了函数模板的典型用法后，我们发现`FunctionTemplateInfo`对象，通常只有三个设置为非默认值。因此，我们将`FunctionTemplateInfo`对象，以便将稀有字段存储在侧表中，该侧表仅在需要时按需分配。

第二个优化与我们如何从 TurboFan 优化代码中取消优化有关。由于 TurboFan 执行推测优化，因此如果某些条件不再成立，它可能需要回退到解释器（取消优化）。每个 deopt 点都有一个 id，使运行时能够确定在字节码中它应该在解释器中返回执行的位置。以前，此 ID 的计算方法是让优化的代码跳转到大型跳转表中的特定偏移量，该跳转表将正确的 ID 加载到寄存器中，然后跳转到运行时以执行取消优化。这样做的好处是，在优化代码中，每个去取点只需要一个跳转指令。但是，去优化跳转表是预先分配的，并且必须足够大以支持整个去优化 ID 范围。相反，我们修改了 TurboFan，使得优化代码中的 deopt 点在调用运行时之前直接加载 deopt id。这使我们能够完全删除这个大型跳转表，但代价是优化的代码大小略有增加。

## 结果

在过去的七个 V8 版本中，我们已经发布了上述优化。通常他们首先降落*精简模式*，然后后来被引入到 V8 的默认配置。

![Average V8 heap size for a set of typical web pages on an AndroidGo device.](../_img/v8-lite/savings-by-release.svg)

![Per-page breakdown of memory savings of V8 v7.8 (Chrome 78) compared to v7.1 (Chrome 71).](../_img/v8-lite/breakdown-by-page.svg)

在这段时间里，我们在一系列典型网站上将 V8 堆大小平均减少了 18%，相当于低端 AndroidGo 移动设备的平均减少了 1.5 MB。这是可能的，而不会对JavaScript性能产生任何重大影响，无论是在基准测试上还是在现实世界的网页交互中测量。

*精简模式*通过禁用函数优化，可以进一步节省内存，但会降低 JavaScript 执行吞吐量。平均*精简模式*节省 22% 的内存，部分页面的内存减少高达 32%。这相当于 AndroidGo 设备上的 V8 堆大小减少了 1.8 MB。

![Breakdown of memory savings of V8 v7.8 (Chrome 78) compared to v7.1 (Chrome 71).](../_img/v8-lite/breakdown-by-optimization.svg)

当按每个单独优化的影响进行拆分时，很明显，不同的页面从每个优化中获得不同比例的收益。展望未来，我们将继续确定潜在的优化，这些优化可以进一步减少V8的内存使用量，同时在JavaScript执行中仍然保持极快的速度。
